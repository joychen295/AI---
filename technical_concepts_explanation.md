# 辰极智脑 - 核心技术概念解析

本文档基于“辰极智脑”的架构设计与代码实现，对系统中的关键技术概念进行深度解析。

---

## 1. LightRAG vs VikingDB：差异对比

在辰极智脑中，这两者是两种不同的 **AI 能力提供者 (Provider)**，它们在架构定位、技术实现和适用场景上有本质区别。

| 维度               | **LightRAG (本地知识图谱)**                                                                                                           | **VikingDB (云端向量检索)**                                                                                                     |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------ |
| **核心定义** | **本地化**的、基于**图谱**的检索增强生成引擎。                                                                                  | **云端**的、基于**向量**的大规模数据库服务。                                                                              |
| **部署方式** | **内嵌部署**。作为服务的一部分运行在本地容器中，<br />数据存储在本地文件或轻量级库中。                                                | **SaaS/PaaS 服务**。<br />通过 API 远程调用云端服务，数据存储在云端集群。                                                       |
| **技术原理** | **GraphRAG (图检索)**。不仅切片，还提取实体（Entity）和关系（Relation），<br />构建知识图谱。擅长回答“宏观”或“跨文档关联”的问题。 | **Vector Search (向量检索)**。将文本转为向量（Embedding），<br />通过余弦相似度找最相似的片段。擅长回答“精准匹配”的细节问题。 |
| **数据隐私** | **极高**。数据不出本地服务器，适合绝密文档。                                                                                          | **中等**。数据需上传至云端（依赖云厂商的安全保障）。                                                                            |
| **典型场景** | 需要深度理解文档间关系（如：A合同条款如何影响B项目）；<br />数据绝对不能出域的场景。                                                        | 海量文档检索（如：百万级企业知识库）；<br />需要高并发、快速响应的场景。                                                              |

**一句话总结**：LightRAG 是“深思熟虑的本地专家”，擅长挖掘复杂关系；VikingDB 是“博闻强记的云端图书管理员”，擅长快速查找海量资料。

---

## 2. 模型能力的“热插拔”与“自动降级”

这两个概念是辰极智脑**高可用性（High Availability）**和**灵活性**的核心体现。

### (1) 热插拔 (Hot-swapping)

* **定义**：指在**不停止服务、不重启系统**的情况下，动态更换底层的 AI 模型或调整配置。
* **在系统中的体现**：
  * 管理员可以在后台将 LLM 从 `GPT-3.5` 切换为 `GPT-4`，或者将 Embedding 模型从 `OpenAI` 切换到 `BGE`。
  * **实现原理**：配置系统（Config Service）采用“委托模式”。当配置更新时，系统内存中的配置对象会即时刷新，下一个请求进来时，直接使用新配置初始化 Provider。
  * **价值**：运营人员可以根据实时的“成本”或“效果”灵活调整策略，无需技术人员半夜爬起来发版重启。

### (2) 自动降级 (Automatic Degradation / Fallback)

* **定义**：当首选的 AI 服务（Plan A）发生故障或不可用时，系统**自动**切换到备选服务（Plan B），确保业务不中断。
* **在系统中的体现**：
  * **场景**：配置首选 `LightRAG` 进行检索，但由于服务器内存不足导致 LightRAG 崩溃。
  * **流程**：代码中的 `ProviderRegistry` 捕获到错误 -> 检查备选列表 -> 自动初始化 `VikingDB` -> 完成用户的查询请求。
  * **价值**：用户无感知。用户只知道“我得到了答案”，而不知道后台已经经历了一次惊心动魄的故障切换。这是企业级服务稳定性的底线。

---

## 3. Redis 的 SSOT (Single Source of Truth) 架构

* **定义**：**单一真相源**。在分布式系统中，确保任何数据（如服务状态）只有**唯一**的一个存储位置是权威的，其他所有地方的数据都只是它的“引用”或“副本”。
* **在系统中的体现**：
  * **权威数据**：`service_registry:{namespace}:services:{instance_id}`。这个 Redis Key 存储了服务的所有元数据（IP、端口、状态）。
  * **衍生索引**：系统为了查询方便，建立了“名称索引”、“健康状态索引”、“路由索引”。
* **为什么重要？**
  * 如果没有 SSOT，可能会出现“索引说服务活着，但服务详情里却找不到它”的**数据不一致**问题。
  * 辰极智脑通过 **Lua 脚本** 保证，当更新 SSOT 时，必须**原子性**地同步更新所有索引。要么全成功，要么全失败，绝不会出现“脏数据”。

---

## 4. “原子注册”、“心跳保活”与“自动剔除”

这是微服务治理的三板斧，用于维护服务注册表的准确性。

### (1) 原子注册 (Atomic Registration)

* **机制**：服务启动时，向 Redis 写入自己的信息。
* **“原子”的含义**：利用 Redis 的 Lua 脚本，将“检查是否有重名冲突”和“写入数据”这两个动作合并成**不可分割的一步**。
* **目的**：防止高并发下，两个服务同时抢占同一个名字（Race Condition）。

### (2) 心跳保活 (Heartbeat Keep-alive)

* **机制**：微服务就像人一样，每隔几秒钟（例如 5秒）向注册中心发送一个“我还在”的信号（HTTP 请求）。
* **目的**：注册中心通过接收心跳来判断服务是否存活。如果服务进程崩溃了（Crash），心跳自然就停止了。

### (3) 自动剔除 (Automatic Eviction)

* **机制**：注册中心有一个后台“清洁工”（HealthChecker）。它定期扫描所有服务，计算 `当前时间 - 最后一次心跳时间`。
* **规则**：如果差值超过阈值（例如 30秒），说明该服务已经“失联”太久。
* **动作**：系统自动将该服务从“健康列表”中移除，甚至直接从数据库中删除。
* **价值**：确保网关不会把用户的请求转发给已经挂掉的服务，避免用户看到“502 Bad Gateway”错误。

---

## 5. 异步切片/向量化 (SSE流式进度) -> 构建索引

这是一个处理耗时任务的标准范式，解决了“用户上传大文件需要漫长等待”的体验问题。

### 流程解析

1. **异步 (Async)**：用户上传文件后，后端立刻返回“收到”，不让前端转圈等待。后台开启一个独立线程/进程去慢慢处理文件。
2. **切片/向量化**：
   * **切片**：把一本 500 页的书，按语义切成 1000 个小段落（Chunks）。
   * **向量化**：调用 Embedding 模型，把这 1000 个段落转换成 1000 组数学向量（机器能懂的数字）。
3. **SSE 流式进度**：后台每处理完 10 个段落，就通过 Server-Sent Events (SSE) 长连接，主动推一条消息给前端：“进度 1%... 进度 5%...”。前端进度条实时跳动。
4. **构建索引**：将这些向量存入数据库（VikingDB 或 LightRAG），建立索引以便快速检索。

### 具体应用场景举例

* **场景一：企业标书分析**

  * **用户行为**：售前经理上传了一份 200MB 的甲方招标文件（PDF）。
  * **系统动作**：文件太大，处理需要 3 分钟。系统在后台默默解析，前端显示“正在学习招标文件... 35%”。
  * **结果**：3分钟后，经理可以直接问：“这次招标对注册资金的要求是多少？”，AI 瞬间给出答案。
* **场景二：法律合规审查**

  * **用户行为**：法务上传了公司过去 10 年的所有合同范本（几千个文件）。
  * **系统动作**：这是一个长达数小时的批量任务。SSE 持续推送日志：“正在处理 2021年采购合同.docx... 已完成”。
  * **结果**：构建完成后，法务可以检索：“过去合同中关于‘不可抗力’的条款通常是怎么写的？”
* **场景三：医疗病历归档**

  * **用户行为**：医生上传患者的电子病历和检查报告。
  * **系统动作**：后台将非结构化的文本转化为结构化的知识图谱（LightRAG）。
  * **结果**：医生后续可以问：“该患者既往是否有青霉素过敏史？”，系统通过图谱关联迅速定位并回答。
